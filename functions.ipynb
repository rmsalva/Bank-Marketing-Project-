{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8162355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que etiqueta el conteo final encima de cada barra del gráfico\n",
    "def label_values(ax, spacing=5):\n",
    "    total = 0\n",
    "    for rect in ax.patches:\n",
    "        total += rect.get_height()\n",
    "\n",
    "    for rect in ax.patches:\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        space = spacing\n",
    "        \n",
    "        va = 'bottom'\n",
    "        \n",
    "        if y_value < 0:\n",
    "            space *= -1\n",
    "            va = 'top'\n",
    "        label = \"{:.2f},  {:.2f} %\".format(y_value, y_value/total*100)\n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),         \n",
    "            xytext=(0, space),          \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91ad894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que detecta los outliers de una feature\n",
    "def outliers_indices(feature):\n",
    "    # 1. Calcula la media de la feature\n",
    "    mid = df[feature].mean()\n",
    "    # 2. Calcula la desviacion estandard de la feature\n",
    "    sigma = df[feature].std()\n",
    "    # 3. Se imprime la media y la estandard por pantalla\n",
    "    print(f'Feature {feature} , media: {mid}, sigma: {sigma}')\n",
    "    # 4. Retorna aquellos ínices que están muy alejados de 3 sigma con respecto a la media\n",
    "    return df[(df[feature] < mid - 3*sigma) | (df[feature] > mid + 3*sigma)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff185087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que procesa el data_frame original\n",
    "\n",
    "def preprocess(df): \n",
    "    \n",
    "    df = df.rename(columns={'y': 'deposit','cons.price.idx':'ipc','default':'debts','housing':'mortgage',\n",
    "                       'duration':'call_duration','campaign':'n_contacts','previous':'n_past_contacts',\n",
    "                        'poutcome':'previous_results', 'pdays': 'days_from_last_campaign','cons.conf.idx':'icc',\n",
    "                        'nr.employed':'n_employed','emp.var.rate':'emp_var_rate'})\n",
    "       \n",
    "    # 1. Se filtran las numéricas para su estandarización posterior\n",
    "    df_numerical = df.select_dtypes(exclude=\"object\") \n",
    "    \n",
    "    # 2. Se binariza la variable target deposit\n",
    "    binarize_n = {'yes':  1, 'no': 0} \n",
    "    df['deposit_n'] = df['deposit'].map(binarize_n)\n",
    "    \n",
    "    # 3. Se codifican las variables debts, mortgage y loan mediante el método LabelEncoder\n",
    "    #coding_n = {'unknown': 0, 'yes': 1, 'no': 2}\n",
    "    from sklearn. preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.debts)\n",
    "    le.fit(df.mortgage)\n",
    "    le.fit(df.loan)\n",
    "    df['debts_n'] = le.transform(df.debts)\n",
    "    df['mortage_n'] = le.transform(df.mortgage)\n",
    "    df['loan_n'] = le.transform(df.loan)\n",
    "\n",
    "    # 4. Se codifican los meses del 1 al 12 secuencialmente \n",
    "    coding_mon = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec':12}\n",
    "    df['month_n'] = df['month'].map(coding_mon)\n",
    "\n",
    "    # 5. Se codifica las variables contact y previous_results según la siguiente codificación\n",
    "    coding_contactd_cont = {'unknown': 0, 'cellular': 1, 'telephone': 2}\n",
    "    df['contact_n'] = df['contact'].map(coding_contactd_cont)\n",
    "    coding_previous_results = {'nonexistent':0, 'failure':1, 'success':2}\n",
    "    df['previous_results_n'] = df['previous_results'].map(coding_previous_results)\n",
    "\n",
    "    # 6. Se codifica el resto de variables como one hot encoding : job, marital, education y day_of_week, \n",
    "    df = pd.get_dummies(df, columns = ['job', 'marital', 'education', 'day_of_week'],drop_first=True)\n",
    "    \n",
    "    # 7. Se eliman algunas variables ya codificadas\n",
    "    df = df.drop(['deposit', 'debts','mortgage', 'loan','month', 'contact', 'previous_results'], axis = 1)\n",
    "    \n",
    "    # 8. Se estandariza todas las variables numéricas\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    \n",
    "    df[df_numerical] = scaler.fit_transform(df[df_numerical])\n",
    "    \n",
    "    # 9. Se retorna el data_frame procesado.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e75a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que procesa el data_frame original como entrada \n",
    "# al modelo ya entrenado. \n",
    "\n",
    "def transform (df,rename=False,scaler=True):\n",
    "    # 1. Se renombran las columnas originales \n",
    "    if rename:\n",
    "        df = df.rename(columns={'y': 'deposit','cons.price.idx':'ipc','default':'debts','housing':'mortgage',\n",
    "                       'duration':'call_duration','campaign':'n_contacts','previous':'n_past_contacts',\n",
    "                        'poutcome':'previous_results', 'pdays': 'days_from_last_campaign','cons.conf.idx':'icc',\n",
    "                        'nr.employed':'n_employed','emp.var.rate':'emp_var_rate'})\n",
    "    \n",
    "    # 2. Se filtran las numéricas para su estandarización posterior\n",
    "    df_numerical = df.select_dtypes(exclude=\"object\") \n",
    "    \n",
    "    # 3. Se eliminan aquellas variables numéricas que no aportan valor predictivo. \n",
    "    df.drop(['emp_var_rate', 'n_employed','call_duration'], axis = 1, inplace=True)\n",
    "    df_numerical = list(set(df_numerical) - set(['emp_var_rate', 'n_employed','call_duration']))\n",
    "    \n",
    "    # 4. Se binariza la variable target deposit\n",
    "    binarize_n = {'yes':  1, 'no': 0} \n",
    "    df['deposit_n'] = df['deposit'].map(binarize_n)\n",
    "    \n",
    "    # 5. Se codifican las variables debts, mortgage y loan mediante el método LabelEncoder\n",
    "    #coding_n = {'unknown': 0, 'yes': 1, 'no': 2}\n",
    "    from sklearn. preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.debts)\n",
    "    le.fit(df.mortgage)\n",
    "    le.fit(df.loan)\n",
    "    df['debts_n'] = le.transform(df.debts)\n",
    "    df['mortage_n'] = le.transform(df.mortgage)\n",
    "    df['loan_n'] = le.transform(df.loan)\n",
    "\n",
    "    # 6. Se codifican los meses del 1 al 12 secuencialmente \n",
    "    coding_mon = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec':12}\n",
    "    df['month_n'] = df['month'].map(coding_mon)\n",
    "\n",
    "    # 7. Se codifica las variables contact y previous_results según la siguiente codificación\n",
    "    coding_contactd_cont = {'unknown': 0, 'cellular': 1, 'telephone': 2}\n",
    "    df['contact_n'] = df['contact'].map(coding_contactd_cont)\n",
    "    coding_previous_results = {'nonexistent':0, 'failure':1, 'success':2}\n",
    "    df['previous_results_n'] = df['previous_results'].map(coding_previous_results)\n",
    "\n",
    "    # 8. Se codifica el resto de variables como one hot encoding : job, marital, education y day_of_week, \n",
    "    df = pd.get_dummies(df, columns = ['job', 'marital', 'education', 'day_of_week'],drop_first=True)\n",
    "    \n",
    "    # 9. Se eliman algunas variables ya codificadas\n",
    "    df = df.drop(['deposit', 'debts','mortgage', 'loan','month', 'contact', 'previous_results'], axis = 1)\n",
    "    \n",
    "    # 10. Se estandariza todas las variables numéricas\n",
    "    if scaler:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = MinMaxScaler()\n",
    "    \n",
    "        df[df_numerical] = scaler.fit_transform(df[df_numerical])\n",
    "    \n",
    "    # 11. Se retorna el data_frame procesado.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d7a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza un infome de clasificación del modelo \n",
    "def report(model):\n",
    "    # 1. Realiza una predicción del modelo\n",
    "    preds = model.predict(x_test)\n",
    "    # 2. Imprime el informe de clasificación en base a las predicciones\n",
    "    print(classification_report(preds,y_test))\n",
    "    #print(\"Precision score: {}\".format(precision_score(preds,y_test)))\n",
    "    # 3. Obtiene la matriz de consfusión \n",
    "    cm = confusion_matrix(y_test, preds, labels=model.classes_)\n",
    "    \n",
    "    #plot_confusion_matrix(model,x_test,y_test)\n",
    "    # 4. Plotea la matriz de confusión\n",
    "    disp=  ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    #plot_precision_recall_curve(model,x_test,y_test)\n",
    "    #plot_roc_curve(model,x_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8741f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo usando el tuneado de hiper-parámetros\n",
    "def training_model_hyperparameter(model, scoring, params_grid, X_train, y_train):\n",
    "    # 1. Se define la validación cruzada repetidas con 10 splits y en modo aleatorio\n",
    "    folds = StratifiedKFold(n_splits = 10, shuffle = True, random_state=100)\n",
    "\n",
    "    # 2. Define la malla especificando hiper-parámetros, estimador, validación cruzada y métrica asociada.\n",
    "    grid = GridSearchCV(estimator = model, scoring=scoring, param_grid = params_grid, cv = folds, \n",
    "                           verbose=0, return_train_score=True, n_jobs=3)\n",
    "    # 3. Entrenamiento del modelo con la configuración anterior. \n",
    "    grid.fit(X_train, y_train)\n",
    "    # 4. Se retorna el modelo entrenado.\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d6ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo predicción y probabilidades en datos de entrenamiento y test.\n",
    "def prediction_model(model, X_train, y_train, X_test, y_test):\n",
    "    # 1. Cálculo predicción de datos de entrenamiento\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # 2. Cálculo probabilidades de datos de entrenamiento\n",
    "    y_train_pred_prob = model.predict_proba(X_train)[:, 1]\n",
    "    # 3. Cálculo predicción de datos de\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # 4. Cálculo probabilidades de datos de test\n",
    "    y_test_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    # 5. Retorna los cálculos realizados. \n",
    "    return y_train_pred, y_train_pred_prob, y_test_pred, y_test_pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "942e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC de la probabilidad de los datos de test y entrenamiento \n",
    "def draw_roc( train_actual, train_probs, test_actual, test_probs ):\n",
    "    train_fpr, train_tpr, train_thresholds = metrics.roc_curve( train_actual, train_probs,\n",
    "                                              drop_intermediate = False )\n",
    "    test_fpr, test_tpr, test_thresholds = metrics.roc_curve( test_actual, test_probs,\n",
    "                                              drop_intermediate = False )\n",
    "    train_auc_score = metrics.roc_auc_score( train_actual, train_probs )\n",
    "    test_auc_score = metrics.roc_auc_score( test_actual, test_probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( train_fpr, train_tpr, label='ROC curve (area = %0.2f)' % train_auc_score )\n",
    "    plt.plot( test_fpr, test_tpr, label='ROC curve (area = %0.2f)' % test_auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59244712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de vbles predictoras con RF\n",
    "\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "\n",
    "# Ploteado de la importancia de vbles predictoras con RF \n",
    "\n",
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100b9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza un infome de clasificación del modelo para un threshold de 0.3\n",
    "def report_threshold(model):\n",
    "    # 1. Cálculo de las predicciones para un umbral de 0.3\n",
    "    preds = (model.predict_proba(x_test)[:,1] >=0.3).astype(bool)\n",
    "    # 2. Se imprime el inforrme de clasificación\n",
    "    print(classification_report(preds,y_test))\n",
    "    # 3. Se calcula la matriz de consusión\n",
    "    cm = confusion_matrix(y_test, preds, labels=model.classes_)\n",
    "    \n",
    "    #4. Se plotea la matriz de confusión.\n",
    "    disp=  ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "    disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
